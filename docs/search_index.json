[["index.html", "pOmics3: Functional Proteomics Data Analysis in R Preface", " pOmics3: Functional Proteomics Data Analysis in R Nico Hüttmann Preface Welcome! This handbook is a reference guide to use the pOmics3 R package for proteomics data analysis. Yes, it’s the third version of an old idea - alle guten Dinge sind 3! For reasons, I decided to rethink the way I analyze data at the beginning of my PhD. It’s basically a collection of ideas, workflows and ideas for myself, which I look up every other time I start a new analysis. Main features: Framework to load, handle and analyze proteomics data tidyverse friendly Statistical analysis of qualitative and quantitative data Functional enrichment analysis via fgsea ggplot2, for publication-quality figures plotly, for interactive data exploration "],["introduction.html", "1 Introduction 1.1 Ressources 1.2 Acknowledgements", " 1 Introduction Welcome to the pOmics3 Handbook! The following chapters will ensure that all necessary software is installed so you can start working with R. First, we will install R and RStudio. Working with R heavily depends on making use of various packages freely available, which we will learn from different sources. To complete our repertoire of necessary tools for data science, we will learn to use Git and GitHub for seamless collaboration and version control. 1.1 Ressources This is a brief listing of resources for proteomics data analysis and R programming on which all following content is based on: More to come 1.2 Acknowledgements Brief thanks to the people which were involved in the early developments of these packages (longer version): Dr. Maxim Berezovski: Freedom to try and learn different solutions to proteomics problems. Dr. Zoran Minic: Challenges to improve creativity and efficiency in proteomics data analysis. Abdullah Khraibah: Motivation to share analysis code and functions. Daniel Torka: Recommended tidyverse and R Markdown long before I started appreciating them. Thanks Junior! "],["r-and-rstudio.html", "2 R and RStudio 2.1 Install the R language 2.2 Install RStudio", " 2 R and RStudio “R is ‘GNU S’, a freely available language and environment for statistical computing and graphics which provides a wide variety of statistical and graphical techniques: linear and nonlinear modelling, statistical tests, time series analysis, classification, clustering, etc.” This is the description of R on the R website. 2.1 Install the R language Download the most recent release of R for your platform from https://cloud.r-project.org/. Install it like any other program. It is important to install R before RStudio. 2.2 Install RStudio RStudio is an integrated development environment (IDE) for R. Other IDEs do exist, but RStudio is the software of choice by far. Like, by far. Download the desktop version of RStudio from https://www.rstudio.com/products/rstudio/. This is the program in which you will interact with the R language and conduct all your analyses. "],["r-packages.html", "3 R packages 3.1 From CRAN 3.2 From Bioconductor 3.3 From GitHub and others sources", " 3 R packages knitr::opts_chunk$set(eval = FALSE) “R packages are collections of functions and data sets developed by the community. They increase the power of R by improving existing base R functionalities, or by adding new ones.”1 Basically, R packages are nothing but collections of functions bundled together in a way that makes sense. Like different cookbooks that only contain recipes for a particular kind of food. They can be installed from many different sources which will be explored below. 3.1 From CRAN The Comprehensive R Archive Network (CRAN) package repository features 18,000+ R packages. Here’s the list of Available CRAN Packages By Name. Most general purpose packages can be found here, however due to reasons, some packages are only available from other sources. As a first example, we will download the tidyverse, a collection of R packages for data science. “The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” We can install packages from CRAN with the install.packages() function like this: install.packages(&quot;tidyverse&quot;) Note, that we can also download more than one package at once using a vector (c()) containing all package names: install.packages(c(&quot;BiocManager&quot;, &quot;devtools&quot;)) BiocManager as well as devtools will be used in the following to download R packages from other sources. 3.2 From Bioconductor The Bioconductor is a collection of R packages for bioinformatics purposes. The first packages we will need from the Bioconductor will be downloaded with the install() function from the BiocManager package: BiocManager::install(c(&quot;fgsea&quot;, &quot;org.Hs.eg.db&quot;, &quot;UniProt.ws&quot;)) 3.3 From GitHub and others sources Another important source of R packages is GitHub. GitHub is not just the place where most R packages are being developed before they are put to repositories such as CRAN or Bioconductor, many other packages including the pOmics3 packages can be installed from it as well. :) Here is an example with the install_github() function from the devtools package which will be further described in Setup pOmics3. devtools::install_github(&quot;nicohuttmann/pOmics3&quot;) There are some other sources for R packages, which we want to use. Here, we are downloading the disgenet2r package to query the DisGeNET database for gene disease associations: devtools::install_bitbucket(&quot;ibi_group/disgenet2r&quot;) https://www.datacamp.com/community/tutorials/r-packages-guide↩︎ "],["version-control-with-github.html", "4 Version control with GitHub 4.1 Headstart into Git and GitHub with RStudio 4.2 Basic GitHub routine 4.3 Common problems", " 4 Version control with GitHub Excuse me, do you have a moment to talk about version control?2 There is a lot to say about GitHub and why one may use it. An extensive discussion on this topic and basically everything you will learn in this chapter can be found in Happy Git and GitHub for the useR. This chapter will introduce the basics on how to collaborate with other people using GitHub, which is probably the reason why you are reading this in the first place. 4.1 Headstart into Git and GitHub with RStudio The following post provides a quick introduction on how to set up Git and GitHub and connect your GitHub account with RStudio: https://www.bioinformatics.babraham.ac.uk/training/RStudio_GitHub/Initial_setup.html. Once this is done, you should be able to connect and download online GitHub repositories and are able to start collaborating on projects immediately. 4.2 Basic GitHub routine Open your Git terminal in R and start with these lines of code. Add files: git add . Commit changes: git commit -m &quot;Add important changes&quot; Push your commits: git push … 4.3 Common problems The following should provide a summary of common problems encountered when using Git. It also serves as a reminder for myself. 4.3.1 Too large files Original post of the answer: https://stackoverflow.com/a/17890278. Download the BFG Repo-Cleaner jar file “bfg-x.xx.x.jar” (e.g. “bfg-1.14.0.jar”) from https://rtyley.github.io/bfg-repo-cleaner/. Place the file in the directory of your R project, the same of the .git folder. Open the terminal in this folder (e.g. via RStudio &gt; Git &gt; Shell…) Type in the terminal: java -jar bfg.jar --strip-blobs-bigger-than 100M The file name “bfg.jar” must match the name of your jar file and the file size limit can be changed (e.g. 50M for 50 ) If you do not encouter an error, type: git gc --prune=now --aggressive to clean the dead data. If you encounter the following error Warning : no large blobs matching criteria found in packfiles - does the repo need to be packed?, refer to this post https://stackoverflow.com/q/61769785 and type git gc prior to step 4. 4.3.2 .gitignore does not instantly work Just do: git rm -r --cached . git add . git commit -m &quot;Drop files from .gitignore&quot; https://peerj.com/preprints/3159v2/↩︎ "],["setup-pomics3.html", "5 Setup pOmics3", " 5 Setup pOmics3 knitr::opts_chunk$set(eval = FALSE) Prior to installing the pOmics3 package, it helps to install required packages separately. This sometimes makes your life easier. install.packages(&quot;tidyverse&quot;) install.packages(c(&quot;vroom&quot;)) Other functions not required for the pOmics3 package but covered in this book can be installed with the following command. # Chapter 4 install.packages(c(&quot;ggvenn&quot;)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;ComplexHeatmap&quot;) install.packages(&quot;magick&quot;) # Chapter 5 install.packages(c(&quot;&quot;)) "],["project-setup.html", "6 Project setup 6.1 Scripts 6.2 Data Structure", " 6 Project setup knitr::opts_chunk$set(eval = FALSE) 6.1 Scripts We should start with a place to save our code 6.2 Data Structure A good idea for every project is to have a simple structure to store your files. Here, I suggest having three main folders: Data to store all you raw data and other files that go into your analysis. In addition, you can create a sub folder to store all your RData files. Scripts to store all your analysis scripts and custom functions written for a specific analysis. Output to store all files, plots and tables that come out of your analysis. Depending on the project size, sub folders for individual figures in a manuscript or file types could be useful. # ---- Setup folders ---- dir.create(&quot;Data&quot;) dir.create(&quot;Data/raw&quot;) dir.create(&quot;Data/RData&quot;) dir.create(&quot;Scripts&quot;) dir.create(&quot;Output&quot;) Now you can add your raw data etc. In this example, we will work with this data frame: … We can visualize the folder structure with the fs::dir_tree function. "],["import-data.html", "7 Import Data 7.1 Packages 7.2 Import data 7.3 Tidy raw data 7.4 Define the first data frame 7.5 Add meta data 7.6 Filter proteins and samples", " 7 Import Data knitr::opts_chunk$set(eval = FALSE) 7.1 Packages All packages including the pOmics3 package must be installed. Go back here to do so here library(tidyverse) #library(pOmics3) ## Collect file names # the pattern argument specificies that we only look for .tsv files files &lt;- list.files(recursive = T, pattern = &quot;\\\\.tsv&quot;) ## this function helps with turning vectors into their code equivalents .cat_character(files) rm(files) We can further specify their names if we have a complicated sub folder structure like this. 7.2 Import data # ---- Create data structure ---- Info &lt;- list(Imports = list()) Datasets &lt;- list() Analysis &lt;- list() # ---- Import data ---- import_files(files = c(# phospho_ion = &quot;Data/PTM/ion.tsv&quot;, # phospho_peptide = &quot;Data/PTM/peptide.tsv&quot;, phospho_protein = &quot;Data/PTM/protein.tsv&quot;, # phospho_psm = &quot;Data/PTM/psm.tsv&quot;, # full_ion = &quot;Data/SP2/ion.tsv&quot;, # full_peptide = &quot;Data/SP2/peptide.tsv&quot;, full_protein = &quot;Data/SP2/protein.tsv&quot;#, #full_psm = &quot;Data/SP2/psm.tsv&quot; )) 7.3 Tidy raw data 7.4 Define the first data frame 7.5 Add meta data 7.6 Filter proteins and samples "],["data-normalization.html", "8 Data normalization 8.1 limma normalization methods 8.2 vsn normalization 8.3 pqn normalization (implemented by pOmics3) 8.4 Group-wise normalization 8.5 Principal component analysis (PCA) 8.6 Differential abundace analysis with limma", " 8 Data normalization 8.1 limma normalization methods data_norm &lt;- data %&gt;% transpose_tibble() %&gt;% tibble2matrix() %&gt;% limma::normalizeBetweenArrays(method = &quot;scale&quot;) %&gt;% matrix2tibble(&quot;variables&quot;) %&gt;% transpose_tibble() 8.2 vsn normalization 8.3 pqn normalization (implemented by pOmics3) 8.4 Group-wise normalization base data_norm &lt;- data %&gt;% mutate(group = groups[observations], .after = &quot;observations&quot;) split(.$group) %&gt;% map(\\(x) { x %&gt;% select(-group) %&gt;% transpose_tibble() %&gt;% tibble2matrix() %&gt;% limma::normalizeBetweenArrays(method = &quot;scale&quot;) %&gt;% matrix2tibble(&quot;variables&quot;) %&gt;% transpose_tibble() }) %&gt;% bind_rows() %&gt;% arrange(match(observations, names(groups))) 8.5 Principal component analysis (PCA) (How to use PCA) base list_pca &lt;- list() list_pca[[&quot;prcomp&quot;]] &lt;- get_data_frame(which = &quot;median&quot;, dataset = &quot;protein&quot;) %&gt;% mutate(across(where(is.numeric), \\(x) c(scale(x)))) %&gt;% tibble2data_frame() %&gt;% prcomp() list_pca[[&quot;p12&quot;]] &lt;- list_pca[[&quot;prcomp&quot;]][[&quot;x&quot;]] %&gt;% matrix2tibble(to.row.names = &quot;observations&quot;) %&gt;% mutate(group = groups[observations], .after = &quot;observations&quot;) %&gt;% ggplot(aes(x = PC1, y = PC2, color = group)) + geom_point() + theme_classic() + scale_color_manual(values = Info$freezing_colors) + coord_fixed() + xlab(&quot;PC1&quot;) + ylab(&quot;PC2&quot;) list_pca[[&quot;p12&quot;]] + xlab(paste0( &quot;PC1 (&quot;, round( with( list(x = list_pca[[&quot;prcomp&quot;]][[&quot;sdev&quot;]]), x^2 / sum(x^2))[1] * 100, 1), &quot;%)&quot;)) + ylab( paste0( &quot;PC2 (&quot;, round( with( list(x = list_pca[[&quot;prcomp&quot;]][[&quot;sdev&quot;]]), x^2 / sum(x^2))[2] * 100, 1), &quot;%)&quot;)) pOmics3 Analysis[[&quot;PCA&quot;]] &lt;- list() Analysis[[&quot;PCA&quot;]][[&quot;prcomp&quot;]] &lt;- get_data_frame(which = &quot;median&quot;, variables = , observations = , dataset = &quot;protein&quot;) %&gt;% mutate(across(where(is.numeric), \\(x) c(scale(x)))) %&gt;% tibble2data_frame() %&gt;% prcomp() Analysis[[&quot;PCA&quot;]][[&quot;p12&quot;]] &lt;- (Analysis[[&quot;PCA&quot;]][[&quot;prcomp&quot;]][[&quot;x&quot;]] %&gt;% matrix2tibble(to.row.names = &quot;observations&quot;) %&gt;% add_observations_data(&quot;group&quot;, dataset = &quot;protein&quot;) %&gt;% add_observations_data(&quot;group2&quot;, dataset = &quot;protein&quot;) %&gt;% ggplot(aes(x = PC1, y = PC2, color = group, shape = group2)) + geom_point() + theme_classic() + theme(panel.background = element_rect(color = &quot;black&quot;)) + #scale_color_manual(values = Info$color_scheme) + coord_fixed()) %&gt;% .set_PCA_labs() %&gt;% .set_continuous_axes(axis.unit.ratio = 1) 8.5.1 Combined PCA plots wrap_plots(list_pca[[&quot;p12&quot;]], Analysis[[&quot;PCA&quot;]][[&quot;p34&quot;]], guides = &quot;collect&quot;) wrap_plots(Analysis[[&quot;PCA&quot;]][[&quot;p12&quot;]], Analysis[[&quot;PCA&quot;]][[&quot;p34&quot;]], guides = &quot;collect&quot;) 8.5.2 How to get creative PCA can be used on subsets of samples or on a subset of proteins of interest. 8.6 Differential abundace analysis with limma # limma list_limma &lt;- list() # Make eset from tibble list_limma[[&quot;eset&quot;]] &lt;- get_data_frame(&quot;median&quot;, variables = , observations = , dataset = &quot;protein&quot;) %&gt;% mutate(across(where(is.numeric), log2)) %&gt;% transpose_tibble() %&gt;% tibble2matrix() %&gt;% Biobase::ExpressionSet() # Describe experimental groups list_limma[[&quot;design&quot;]] &lt;- model.matrix( ~0+factor( get_observations_data( which = &quot;group&quot;, observations = , output.type = &quot;vector&quot;, dataset = &quot;protein&quot;), levels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;))) # order of groups colnames(list_limma[[&quot;design&quot;]]) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) # same as levels above # Do first linear model fit list_limma[[&quot;fit&quot;]] &lt;- lmFit(list_limma[[&quot;eset&quot;]], list_limma[[&quot;design&quot;]]) # Describe comparisons (contrasts) list_limma[[&quot;contrast.matrix&quot;]] &lt;- makeContrasts(B-A, C-A, B-C, # describe desired comparison levels = list_limma[[&quot;design&quot;]]) # Compute contrasts list_limma[[&quot;fit2&quot;]] &lt;- contrasts.fit(list_limma[[&quot;fit&quot;]], list_limma[[&quot;contrast.matrix&quot;]]) # Apply empirical bayes statistics list_limma[[&quot;fit2_eBayes&quot;]] &lt;- eBayes(list_limma[[&quot;fit2&quot;]]) p.threshold &lt;- 0.05 fc.threshold.hit &lt;- 1 p.adjust.method &lt;- &quot;BH&quot; # Tidy up results list_limma[[&quot;results&quot;]] &lt;- biobroom::tidy.MArrayLM(list_limma[[&quot;fit2_eBayes&quot;]]) %&gt;% # do p-value correction group_by(term) %&gt;% mutate(p.adjust = p.adjust(p.value, method = p.adjust.method), .after = &quot;p.value&quot;) %&gt;% ungroup() # mutate(regulation = &quot;none&quot;, regulation = ifelse(p.adjust &lt; p.threshold &amp; estimate &gt;= fc.threshold.hit, &quot;hit.up&quot;, regulation), regulation = ifelse(p.adjust &lt; p.threshold &amp; estimate &lt;= - fc.threshold.hit, &quot;hit.down&quot;, regulation)) %&gt;% split(.$term) Add candidates if wanted # regulation = ifelse(p.value &lt; p.threshold &amp; estimate &gt;= fc.threshold.candidate, # &quot;candidate.up&quot;, # regulation), # regulation = ifelse(p.value &lt; p.threshold &amp; estimate &lt;= - fc.threshold.candidate, # &quot;candidate.down&quot;, # regulation), Add protein and gene names. list_limma[[&quot;results&quot;]] &lt;- list_limma[[&quot;results&quot;]] %&gt;% rename(variables = gene) %&gt;% mutate(Protein.name = pull(Info[[&quot;Databases&quot;]][[&quot;UniProt&quot;]], &quot;Protein names&quot;, &quot;Entry&quot;)[variables], Gene.name = pull(Info[[&quot;Databases&quot;]][[&quot;UniProt&quot;]], &quot;Gene Names&quot;, &quot;Entry&quot;)[variables], .after = 1) %&gt;% list_limma[[&quot;p&quot;]] &lt;- names(list_limma[[&quot;results&quot;]]) %&gt;% map(\\(x) ggplot(list_limma[[&quot;results&quot;]][[x]], aes(x = estimate, y = -log10(p.value), color = regulation, Protein.name = Protein.name, Gene.name = Gene.name)) + geom_point() + scale_color_manual(values = c(none = &quot;grey&quot;, hit.up = &quot;red&quot;, hit.down = &quot;blue&quot;)) + ggtitle(x)) Analysis[[&quot;Liver_total_limma&quot;]] &lt;- list_limma patchwork::wrap_plots(Analysis[[&quot;Liver_total_limma&quot;]][[&quot;p&quot;]], guides = &quot;collect&quot;) plotly::ggplotly(Analysis[[&quot;Liver_total_limma&quot;]][[&quot;p&quot;]][[1]]) "],["list-of-functions.html", "9 List of functions 9.1 Data structure", " 9 List of functions 9.1 Data structure 9.1.1 Import data functions import_files .save_import 9.1.2 Dataset functions new_dataset save_dataset import2new_dataset get_dataset get_dataset_names data_frame2new_dataset 9.1.3 Variables functions get_variables get_variables_data get_variables_data_names save_variables_data 9.1.4 Observations functions get_observations get_observations_data get_observations_data_names save_observations_data 9.1.5 Dataset functions get_data_frame get_data_frame_names save_data_frame 9.1.6 Data handling helpers tibble2matrix tibble2data_frame matrix2tibble data_frame2tibble data2tibble transpose_tibble list2logical_df 9.1.7 strsplit helper functions strsplit strsplit_keep strsplit_keep_first strsplit_keep_firstn strsplit_keep_last strsplit_keep_lastn str_locate_last str_rev 9.1.8 Code helpers .cat_character .cat_character_named .cat_numeric .cat_function .identify_observations "],["appendix-b.html", "10 Appendix B 10.1 Rename files based on sub folders", " 10 Appendix B 10.1 Rename files based on sub folders ## Collect file names # the pattern argument specificies that we only look for .tsv files files &lt;- list.files(recursive = T, pattern = &quot;\\\\.tsv&quot;) names(files) &lt;- files %&gt;% gsub(&quot;\\\\.tsv&quot;, &quot;&quot;, .) %&gt;% gsub(&quot;/&quot;, &quot;_&quot;, .) %&gt;% gsub(&quot;Data_&quot;, &quot;&quot;, .) ## this function helps with turning vectors into their code equivalents .cat_character_named(files) rm(files) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
